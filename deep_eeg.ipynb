{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import sklearn.cluster\n",
    "import sklearn.preprocessing\n",
    "import sklearn.neural_network\n",
    "import sklearn.linear_model\n",
    "import sklearn.model_selection\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "numeros = sklearn.datasets.load_digits()\n",
    "imagenes = numeros['images']  # Hay 1797 digitos representados en imagenes 8x8\n",
    "n_imagenes = len(imagenes)\n",
    "X = imagenes.reshape((n_imagenes, -1)) # para volver a tener los datos como imagen basta hacer data.reshape((n_imagenes, 8, 8))\n",
    "Y = numeros['target']\n",
    "print(np.shape(X), np.shape(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 20\n",
    "net = torch.nn.Sequential(\n",
    "                torch.nn.Linear(64, hidden_size),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_size, 10)\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.2) #lr: learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv1d(1, 10, kernel_size=8, stride=1),\n",
    "    torch.nn.MaxPool1d(kernel_size=3),\n",
    "    torch.nn.Conv1d(10, 1, kernel_size=2, stride=1),\n",
    "    torch.nn.Linear(18, 10)\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2) #lr: learning rate\n",
    "epochs = 60\n",
    "loss_values = np.zeros(epochs)\n",
    "F1_values_train = np.zeros(epochs)\n",
    "F1_values_test = np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    X_new = np.expand_dims(X_train, 1) \n",
    "    inputs = torch.autograd.Variable(torch.Tensor(X_new).float())\n",
    "    targets = torch.autograd.Variable(torch.Tensor(Y_train).long())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    out = model(inputs)\n",
    "    out = out.squeeze(dim=1) # necesario para quitar la dimension intermedia de channel\n",
    "    loss = criterion(out, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    values, Y_predicted = torch.max(out.data, 1)\n",
    "    loss_values[epoch] = loss.item()\n",
    "    F1_values_train[epoch] = sklearn.metrics.f1_score(Y_train, Y_predicted, average='macro')\n",
    "    \n",
    "    X_new = np.expand_dims(X_test, 1)\n",
    "    inputs_test = torch.autograd.Variable(torch.Tensor(X_new).float())\n",
    "    out_test = model(inputs_test)\n",
    "    out_test = out_test.squeeze(dim=1)\n",
    "    values, Y_predicted_test = torch.max(out_test.data, 1)\n",
    "    F1_values_test[epoch] = sklearn.metrics.f1_score(Y_test, Y_predicted_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), loss_values)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), F1_values_train, label='train')\n",
    "plt.plot(np.arange(epochs), F1_values_test, label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(epochs), F1_values_train, label='train')\n",
    "plt.plot(np.arange(epochs), F1_values_test, label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('F1')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
